Homework 5
================
Matthew T. Russell

# Problem 1

``` r
wapo_csv_url <- "https://raw.githubusercontent.com/washingtonpost/data-homicides/master/homicide-data.csv"

homicides <- read_csv(wapo_csv_url)
```

The raw data from The Washington Post contains 52179 observations and 12
columns where each observation represents a homicide from the last
decade in the 50 largest American cities. Each observation includes
demographic information pertaining to the victim (name \[`victim_last`,
`victim_first`\], race \[`victim_race`\], age at time of death
\[`victim_age`\], and sex \[`victim sex`\]) along with the coordinates
of the murder (`lat`, `lon`) and whether an arrest was made
(`disposition`).

###### Create a city\_state variable (e.g. “Baltimore, MD”) and then summarize within cities to obtain the total number of homicides and the number of unsolved homicides (those for which the disposition is “Closed without arrest” or “Open/No arrest”).

``` r
homicides <-
  homicides %>% 
    mutate(
      state = ifelse(city == "Tulsa", "OK", state), 
      city_state = str_c(city, ", ", state), 
      reported_date = as.character(reported_date) %>% 
        as_date(format = "%Y%m%d")
    ) %>% 
    relocate(
      city_state, .after = state
    )

homicides_per_city <-
  homicides %>% 
    mutate(
      case = ifelse(disposition %in% c("Closed without arrest", "Open/No arrest"), "unsolved", "solved")
    ) %>% 
    group_by(city_state, case) %>% 
    summarize(
      homicide_count = n()
    )

homicides_per_city_total <- 
    homicides_per_city %>% 
    group_by(city_state) %>% 
    summarize(
      homicide_count = sum(homicide_count)
    ) %>% 
    mutate(
      case = "total"
    ) %>% 
    relocate(case, .after = city_state)

homicides_per_city <-
  bind_rows(homicides_per_city, homicides_per_city_total) %>% 
  mutate(
    case = factor(case, levels = c("solved", "unsolved", "total"))
  ) %>% 
  arrange(city_state, case) %>% 
  filter(case != "solved") %>% 
  pivot_wider(
    names_from = "case", 
    values_from = "homicide_count"
  ) 
```

###### For the city of Baltimore, MD, use the prop.test function to estimate the proportion of homicides that are unsolved; save the output of prop.test as an R object, apply the broom::tidy to this object and pull the estimated proportion and confidence intervals from the resulting tidy dataframe.

``` r
baltimore_prop_tbl <-
  homicides_per_city %>% 
  filter(city_state == "Baltimore, MD")

baltimore_prop <-
  prop.test(pull(baltimore_prop_tbl, unsolved), pull(baltimore_prop_tbl, total)) %>% 
  broom::tidy() %>% 
  select(estimate, conf.low, conf.high)
```

The estimated proportion of unsolved homicides in the last decade from
Baltimore, MD is 0.6455607 with a 95% confidence interval of (0.6275625,
0.6631599).

###### Now run prop.test for each of the cities in your dataset, and extract both the proportion of unsolved homicides and the confidence interval for each. Do this within a “tidy” pipeline, making use of purrr::map, purrr::map2, list columns and unnest as necessary to create a tidy dataframe with estimated proportions and CIs for each city.

``` r
all_cities_test <- function(df) {
  prop.test(x = pull(df, unsolved), n = pull(df, total)) %>% 
    broom::tidy() %>% 
    select(estimate, conf.low, conf.high)
}

homicides_nest <-
  nest(homicides_per_city, data = unsolved:total)

prop_ci_city <-
  homicides_nest %>% 
    mutate(
      prop_95_CI = map(data, all_cities_test)
    ) %>% 
    select(!(data)) %>% 
    unnest(cols = prop_95_CI) %>% 
    rename(lower_limit_95 = conf.low, upper_limit_95 = conf.high)
```

Create a plot that shows the estimates and CIs for each city – check out
geom\_errorbar for a way to add error bars based on the upper and lower
limits. Organize cities according to the proportion of unsolved
homicides.

``` r
prop_ci_city %>% 
  ggplot(aes(x = fct_reorder(city_state, estimate), y = estimate, color = city_state)) +
  geom_point(aes(color = city_state)) +
  geom_errorbar(aes(ymin = lower_limit_95, ymax = upper_limit_95), width = 0.5) +
  coord_flip() +
  ylab("Estimate") +
  xlab("Location") +
  theme(
    legend.position = "none",
    axis.text.y = element_text(size = 8.5)
    )
```

![](p8105_hw5_mtr2143_files/figure-gfm/plot%20geom_errorbar-1.png)<!-- -->

# Problem 2

Create a tidy dataframe containing data from all participants, including
the subject ID, arm, and observations over time:

Start with a dataframe containing all file names; the list.files
function will help

Iterate over file names and read in data for each subject using
purrr::map and saving the result as a new variable in the dataframe

Tidy the result; manipulate file names to include control arm and
subject ID, make sure weekly observations are “tidy”, and do any other
tidying that’s necessary

``` r
file_names <- list.files(path = "./Data")

long_data <- 
  tibble(file_names) %>%
  mutate(
    file_contents = map(file_names, ~ read_csv(file.path("./Data", .))) 
  ) %>% 
  unnest(file_contents) %>% 
  mutate(
    tx_arm = ifelse(str_detect(file_names, "^con_") == T, "control", "experimental") %>% 
      factor(levels = c("control", "experimental")), 
    subject_id = str_extract(file_names, "[:digit:][:digit:]")
    ) %>% 
  relocate(c("tx_arm", "subject_id"), .after = file_names) %>% 
  select(!(file_names)) %>% 
  pivot_longer(
    cols = starts_with("week_"), 
    names_to = "week",
    names_prefix = "week_",
    values_to = "value"
  ) %>% 
  mutate(
    week = factor(week, ordered = T)
  )
```

``` r
long_data %>% 
  ggplot(aes(x = week, y = value, group = interaction(tx_arm, subject_id), color = tx_arm)) +
  geom_line() +
  geom_smooth(aes(group = tx_arm)) +
  facet_grid(. ~ tx_arm) +
  xlab("Week") + ylab("Value") +
  theme(
    legend.position = "none"
  )
```

![](p8105_hw5_mtr2143_files/figure-gfm/spaghetti%20plot-1.png)<!-- -->

We notice that there is a positive linear trend over time in the
experimental arm that is absent from the control arm. These is nearly no
observable trend in the control arm. The maximum value in the control
arm is observed at week 5, while the maximum value in the experimental
arm is observed at week 7.

# Problem 3

There are two cases to address:

For numeric variables, you should fill in missing values with the mean
of non-missing values For character variables, you should fill in
missing values with “virginica”

Write a function that takes a vector as an argument; replaces missing
values using the rules defined above; and returns the resulting vector.
Apply this function to the columns of iris\_with\_missing using a map
statement.

``` r
set.seed(10)

iris_with_missing <- iris %>% 
  map_df(~replace(.x, sample(1:150, 20), NA)) %>%
  mutate(Species = as.character(Species))

replace_missing_iris <- function(vec) {
  
  if (is.numeric(vec)) {
    vec = ifelse(is.na(vec) == T, mean(vec, na.rm = T), vec)
  } else if (is.character(vec)) {
    vec = ifelse(is.na(vec) == T, "virginica", vec)
  } else {
    stop("Argument must be a numeric or character vector")
  }
  vec
}

iris_no_missing <- 
  as.list(iris_with_missing) %>% 
  map_df(replace_missing_iris)
```
