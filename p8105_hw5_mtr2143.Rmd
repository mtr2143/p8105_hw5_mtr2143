---
title: "Homework 5"
author: Matthew T. Russell
output: github_document
---

```{r setup, include=FALSE}
library(tidyverse)
library(rvest)
library(lubridate)
library(knitr)

theme_set(theme_minimal() + theme(legend.position = "bottom"))
options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)
scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d
```

# Problem 1

###### Read in data  

```{r, load wapo data, message=FALSE, warning=FALSE}

wapo_csv_url <- "https://raw.githubusercontent.com/washingtonpost/data-homicides/master/homicide-data.csv"

homicides_data <- read_csv(wapo_csv_url)
```

The raw data from The Washington Post contains `r nrow(homicides_data)` observations and `r ncol(homicides_data)` columns where each observation represents a homicide from the last decade in the 50 largest American cities. Each observation includes demographic information pertaining to the victim (name [`victim_last`, `victim_first`], race [`victim_race`], age at time of death [`victim_age`], and sex [`victim sex`]) along with the coordinates of the murder (`lat`, `lon`) and whether an arrest was made (`disposition`). 

###### Create a city_state variable and then summarize within cities to obtain the total number of homicides and the number of unsolved homicides

```{r, add city-state column, message=FALSE}
homicides <-
  homicides_data %>% 
    mutate(
      state = ifelse(city == "Tulsa", "OK", state) %>% 
        str_to_upper(), 
      city_state = str_c(city, ", ", state), 
      reported_date = as.character(reported_date) %>% 
        as_date(format = "%Y%m%d")
    ) %>% 
    relocate(
      city_state, .after = state
    )

homicides_per_city <-
  homicides %>% 
    mutate(
      case = ifelse(disposition %in% c("Closed without arrest", "Open/No arrest"), "unsolved", "solved")
    ) %>% 
    group_by(city_state, case) %>% 
    summarize(
      homicide_count = n()
    )

homicides_per_city_total <- 
    homicides_per_city %>% 
    group_by(city_state) %>% 
    summarize(
      homicide_count = sum(homicide_count)
    ) %>% 
    mutate(
      case = "total"
    ) %>% 
    relocate(case, .after = city_state)

homicides_per_city <-
  bind_rows(homicides_per_city, homicides_per_city_total) %>% 
  mutate(
    case = factor(case, levels = c("solved", "unsolved", "total"))
  ) %>% 
  arrange(city_state, case) %>% 
  filter(case != "solved") %>% 
  pivot_wider(
    names_from = "case", 
    values_from = "homicide_count"
  ) 

homicides_per_city %>% 
  kable(caption = "Number of Unsolved and Total Homicides per 50 Most Populous Cities, 2007-2017")
```

When running this data, I noticed there was an observation with a `uid` corresponding to Tulsa and `city == "Tulsa"` but `state == "AL"`, so I updated this observation so that `state == "OK"`. I also noticed a slight inconsistency in casing of `state`, so I converted it all upper case. 

###### For the city of Baltimore, MD, use the prop.test function to estimate the proportion of homicides that are unsolved.

```{r Baltimore prop test, message=FALSE}
baltimore_prop_tbl <-
  homicides_per_city %>% 
  filter(city_state == "Baltimore, MD")

baltimore_prop <-
  prop.test(pull(baltimore_prop_tbl, unsolved), pull(baltimore_prop_tbl, total)) %>% 
  broom::tidy() %>% 
  select(estimate, conf.low, conf.high)
```

The estimated proportion of unsolved homicides in the last decade from Baltimore, MD is `r pull(baltimore_prop, estimate)` with a 95% confidence interval of (`r pull(baltimore_prop, conf.low)`, `r pull(baltimore_prop, conf.high)`).

###### Run prop.test for each of the cities in your dataset, and extract both the proportion of unsolved homicides and the confidence interval for each. 

```{r, prop test for all cities, message=FALSE}
all_cities_test <- function(df) {
  prop.test(x = pull(df, unsolved), n = pull(df, total)) %>% 
    broom::tidy() %>% 
    select(estimate, conf.low, conf.high)
}

homicides_nest <-
  nest(homicides_per_city, data = unsolved:total)

prop_ci_city <-
  homicides_nest %>% 
    mutate(
      prop_95_CI = map(data, all_cities_test)
    ) %>% 
    select(!(data)) %>% 
    unnest(cols = prop_95_CI) %>% 
    rename(lower_limit_95 = conf.low, upper_limit_95 = conf.high)

prop_ci_city %>% 
  kable(caption = "Estimated Proportion & 95% CI of Unsolved Homicides in 50 Most Populated American Cities, 2007-2017")
```

###### Plot of Unsolved Homicides

```{r, plot geom_errorbar, fig.dim = c(8, 6), message=FALSE}
prop_ci_city %>% 
  ggplot(aes(x = fct_reorder(city_state, estimate), y = estimate, color = city_state)) +
  geom_point(aes(color = city_state)) +
  geom_errorbar(aes(ymin = lower_limit_95, ymax = upper_limit_95), width = 0.5) +
  coord_flip() +
  ylab("Estimate") +
  xlab("Location") +
  theme(
    legend.position = "none",
    axis.text.y = element_text(size = 8.5)
    )
```

# Problem 2

###### Create a tidy dataframe containing data from all participants, including the subject ID, arm, and observations over time

```{r, message=FALSE}
file_names <- list.files(path = "./Data")

long_data <- 
  tibble(file_names) %>%
  mutate(
    file_contents = map(file_names, ~ read_csv(file.path("./Data", .))) 
  ) %>% 
  unnest(file_contents) %>% 
  mutate(
    tx_arm = ifelse(str_detect(file_names, "^con_") == T, "control", "experimental") %>% 
      factor(levels = c("control", "experimental")), 
    subject_id = str_extract(file_names, "[:digit:][:digit:]")
    ) %>% 
  relocate(c("tx_arm", "subject_id"), .after = file_names) %>% 
  select(!(file_names)) %>% 
  pivot_longer(
    cols = starts_with("week_"), 
    names_to = "week",
    names_prefix = "week_",
    values_to = "value"
  ) %>% 
  mutate(
    week = factor(week, ordered = T)
  )
```

The tidied data set has four columns: 

* `tx_arm`:  either control or experimental
* `subject_id`: participant's subject ID that ranges from 01-10 per `tx_arm`  
* `week`: week of observation, ranging from `r min(pull(long_data, week))` to `r max(pull(long_data, week))`
* `value`: recorded value for participant at that week

```{r, spaghetti plot, fig.dim = c(8, 6), message=FALSE}
long_data %>% 
  ggplot(aes(x = week, y = value, group = interaction(tx_arm, subject_id), color = tx_arm)) +
  geom_line() +
  geom_smooth(aes(group = tx_arm)) +
  facet_grid(. ~ tx_arm) +
  xlab("Week") + ylab("Value") +
  theme(
    legend.position = "none"
  )
```

We notice that there is a positive linear trend over time in the experimental arm that is absent from the control arm. These is nearly no observable trend in the control arm. The maximum value in the control arm is observed at week 5, while the maximum value in the experimental arm is observed at week 7. 

# Problem 3

There are two cases to address:

For numeric variables, you should fill in missing values with the mean of non-missing values
For character variables, you should fill in missing values with "virginica"

Write a function that takes a vector as an argument; replaces missing values using the rules defined above; and returns the resulting vector. Apply this function to the columns of iris_with_missing using a map statement.

```{r, load iris}
set.seed(10)

iris_with_missing <- iris %>% 
  map_df(~replace(.x, sample(1:150, 20), NA)) %>%
  mutate(Species = as.character(Species))

replace_missing_iris <- function(vec) {
  
  if (is.numeric(vec)) {
    vec = ifelse(is.na(vec) == T, mean(vec, na.rm = T), vec)
  } else if (is.character(vec)) {
    vec = ifelse(is.na(vec) == T, "virginica", vec)
  } else {
    stop("Argument must be a numeric or character vector")
  }
  vec
}

iris_no_missing <- 
  as.list(iris_with_missing) %>% 
  map_df(replace_missing_iris)
```

